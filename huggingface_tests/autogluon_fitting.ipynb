{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PJATK\\Dyplom\\automated_flat_3D_models_generator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# predict using autogluon\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images_features = pd.read_parquet('./cropped_images_features.parquet')\n",
    "not_cropped_images_features = pd.read_parquet('./not_cropped_images_features.parquet')\n",
    "# combine the two dataframes\n",
    "df = pd.concat([cropped_images_features, not_cropped_images_features])\n",
    "# mix the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241216_091549\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       4.62 GB / 15.37 GB (30.1%)\n",
      "Disk Space Avail:   189.84 GB / 931.51 GB (20.4%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (21207 samples, 87.2 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"d:\\PJATK\\Dyplom\\automated_flat_3D_models_generator\\huggingface_tests\\AutogluonModels\\ag-20241216_091549\"\n",
      "Train Data Rows:    21207\n",
      "Train Data Columns: 1024\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(1), np.int64(0)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4729.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 82.84 MB (1.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['0', '1', '2', '3', '4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 82.84 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 19086, Val Rows: 2121\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7256\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6832\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8006\t = Validation score   (accuracy)\n",
      "\t17.93s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8034\t = Validation score   (accuracy)\n",
      "\t24.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.2`.\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7685\t = Validation score   (accuracy)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t5.32s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.2`. \n",
      "Fitting model: XGBoost ...\n",
      "\tWarning: Exception caused XGBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.2`.\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9604\t = Validation score   (accuracy)\n",
      "\t150.93s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.2`.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.667, 'KNeighborsDist': 0.333}\n",
      "\t0.9613\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 216.26s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3185.0 rows/s (2121 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2121 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\PJATK\\Dyplom\\automated_flat_3D_models_generator\\huggingface_tests\\AutogluonModels\\ag-20241216_091549\")\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "label = 'label'\n",
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.963410</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.065512</td>\n",
       "      <td>150.930152</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>0.065512</td>\n",
       "      <td>150.930152</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.962656</td>\n",
       "      <td>0.961339</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.588685</td>\n",
       "      <td>0.665930</td>\n",
       "      <td>151.578706</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.069609</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.796680</td>\n",
       "      <td>0.803395</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.201182</td>\n",
       "      <td>0.084921</td>\n",
       "      <td>24.639985</td>\n",
       "      <td>0.201182</td>\n",
       "      <td>0.084921</td>\n",
       "      <td>24.639985</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.784232</td>\n",
       "      <td>0.800566</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.219850</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>17.925622</td>\n",
       "      <td>0.219850</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>17.925622</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.762354</td>\n",
       "      <td>0.780764</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.232606</td>\n",
       "      <td>0.089882</td>\n",
       "      <td>5.316005</td>\n",
       "      <td>0.232606</td>\n",
       "      <td>0.089882</td>\n",
       "      <td>5.316005</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.759902</td>\n",
       "      <td>0.768505</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.275814</td>\n",
       "      <td>0.090147</td>\n",
       "      <td>5.301010</td>\n",
       "      <td>0.275814</td>\n",
       "      <td>0.090147</td>\n",
       "      <td>5.301010</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.705960</td>\n",
       "      <td>0.725601</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.492766</td>\n",
       "      <td>0.614019</td>\n",
       "      <td>0.579883</td>\n",
       "      <td>1.492766</td>\n",
       "      <td>0.614019</td>\n",
       "      <td>0.579883</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.664655</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.443747</td>\n",
       "      <td>0.599403</td>\n",
       "      <td>0.578945</td>\n",
       "      <td>1.443747</td>\n",
       "      <td>0.599403</td>\n",
       "      <td>0.578945</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0       NeuralNetTorch    0.963410   0.960396    accuracy        0.143354   \n",
       "1  WeightedEnsemble_L2    0.962656   0.961339    accuracy        1.588685   \n",
       "2     RandomForestEntr    0.796680   0.803395    accuracy        0.201182   \n",
       "3     RandomForestGini    0.784232   0.800566    accuracy        0.219850   \n",
       "4       ExtraTreesEntr    0.762354   0.780764    accuracy        0.232606   \n",
       "5       ExtraTreesGini    0.759902   0.768505    accuracy        0.275814   \n",
       "6       KNeighborsUnif    0.705960   0.725601    accuracy        1.492766   \n",
       "7       KNeighborsDist    0.664655   0.683168    accuracy        1.443747   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.065512  150.930152                 0.143354                0.065512   \n",
       "1       0.665930  151.578706                 0.001584                0.001015   \n",
       "2       0.084921   24.639985                 0.201182                0.084921   \n",
       "3       0.085470   17.925622                 0.219850                0.085470   \n",
       "4       0.089882    5.316005                 0.232606                0.089882   \n",
       "5       0.090147    5.301010                 0.275814                0.090147   \n",
       "6       0.614019    0.579883                 1.492766                0.614019   \n",
       "7       0.599403    0.578945                 1.443747                0.599403   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0         150.930152            1       True          7  \n",
       "1           0.069609            2       True          8  \n",
       "2          24.639985            1       True          4  \n",
       "3          17.925622            1       True          3  \n",
       "4           5.316005            1       True          6  \n",
       "5           5.301010            1       True          5  \n",
       "6           0.579883            1       True          1  \n",
       "7           0.578945            1       True          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 1000,\n",
       " 'epochs_wo_improve': None,\n",
       " 'activation': 'relu',\n",
       " 'embedding_size_factor': 1.0,\n",
       " 'embed_exponent': 0.56,\n",
       " 'max_embedding_dim': 100,\n",
       " 'y_range': None,\n",
       " 'y_range_extend': 0.05,\n",
       " 'dropout_prob': 0.1,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.0003,\n",
       " 'weight_decay': 1e-06,\n",
       " 'proc.embed_min_categories': 4,\n",
       " 'proc.impute_strategy': 'median',\n",
       " 'proc.max_category_levels': 100,\n",
       " 'proc.skew_threshold': 0.99,\n",
       " 'use_ngram_features': False,\n",
       " 'num_layers': 4,\n",
       " 'hidden_size': 128,\n",
       " 'max_batch_size': 512,\n",
       " 'use_batchnorm': False,\n",
       " 'loss_function': 'auto'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hyperparameters of the best model\n",
    "predictor.info()['model_info']['NeuralNetTorch']['hyperparameters']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
